{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components:\n",
    "- torch.utils.data.Dataset\n",
    "- Tokenizer\n",
    "- Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/haocai1992/GPT2-News-Classifier/blob/main/colab-train/gpt2-news-classifier-colab-train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from transformers import GPT2Model, GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./data/bbc/learn-ai-bbc/BBC News Train.csv').rename(columns={'Category': 'category', 'Text': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./data/bbc/learn-ai-bbc/BBC News Test.csv').rename(columns={'Category': 'category', 'Text': 'text'})\n",
    "df_sol = pd.read_csv(\"./data/bbc/learn-ai-bbc/BBC News Sample Solution.csv\")\n",
    "\n",
    "df_test = df_test.set_index('ArticleId').join(df_sol.set_index('ArticleId')).rename(columns={'Category': 'category'})\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([df_train, df_test]).drop(columns=['ArticleId']).reset_index(drop=True)\n",
    "df = df_train\n",
    "\n",
    "df = df.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"category\").size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model)\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "example_text = \"I will watch Memento tonight, I heard it's a good movie.\"\n",
    "gpt2_input = tokenizer(example_text, padding=\"max_length\", max_length=20, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "print(\"Input:\")\n",
    "print(gpt2_input['input_ids'])\n",
    "print()\n",
    "\n",
    "print(\"Attention mask:\")\n",
    "print(gpt2_input[\"attention_mask\"])\n",
    "print()\n",
    "\n",
    "print(\"Decoded:\")\n",
    "example_text = tokenizer.decode(gpt2_input.input_ids[0])\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model)\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "labels = {\n",
    "    \"business\": 0,\n",
    "    \"entertainment\": 1,\n",
    "    \"sport\": 2,\n",
    "    \"tech\": 3,\n",
    "    \"politics\": 4\n",
    "         }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [labels[label] for label in df['category']]\n",
    "        self.texts = [tokenizer(text,\n",
    "                                padding='max_length',\n",
    "                                max_length=128,\n",
    "                                truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['text']]\n",
    "        \n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def get_batch_labels(self, idx):\n",
    "        # Get a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "    \n",
    "    def get_batch_texts(self, idx):\n",
    "        # Get a batch of inputs\n",
    "        return self.texts[idx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=35),\n",
    "                                     [int(0.8*len(df)), int(0.9*len(df))])\n",
    "\n",
    "print(len(df_train), len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGPT2SequenceClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes:int, max_seq_len:int, gpt_model_name:str):\n",
    "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
    "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
    "        self.fc1 = nn.Linear(hidden_size*max_seq_len, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "                input_id: encoded inputs ids of sent.\n",
    "        \"\"\"\n",
    "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        batch_size = gpt_out.shape[0]\n",
    "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
    "        return linear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "    \n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    # use_mps = torch.backends.mps.is_available()\n",
    "    # device = torch.device('mps' if use_mps else 'cpu')\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # if use_cuda:\n",
    "    #     model = model.cuda()\n",
    "    #     criterion = criterion.cuda()\n",
    "\n",
    "    # if use_mps:\n",
    "    #     model = model.mps()\n",
    "    #     criterion = criterion.mps()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "        \n",
    "        for train_input, train_label in tqdm(train_dataloader):\n",
    "            train_label = train_label.to(device)\n",
    "            mask = train_input['attention_mask'].to(device)\n",
    "            input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "            \n",
    "            model.zero_grad()\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "            \n",
    "            batch_loss = criterion(output, train_label)\n",
    "            total_loss_train += batch_loss.item()\n",
    "            \n",
    "            acc = (output.argmax(dim=1)==train_label).sum().item()\n",
    "            total_acc_train += acc\n",
    "\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        total_acc_val = 0\n",
    "        total_loss_val = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for val_input, val_label in val_dataloader:\n",
    "                val_label = val_label.to(device)\n",
    "                mask = val_input['attention_mask'].to(device)\n",
    "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "                \n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, val_label)\n",
    "                total_loss_val += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1)==val_label).sum().item()\n",
    "                total_acc_val += acc\n",
    "                \n",
    "            print(\n",
    "            f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train/len(train_data): .3f} \\\n",
    "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
    "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
    "            | Val Accuracy: {total_acc_val / len(val_data): .3f}\")\n",
    "            \n",
    "EPOCHS = 1\n",
    "model = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128, gpt_model_name=model)\n",
    "LR = 1e-5\n",
    "\n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100%|██████████| 596/596 [04:27<00:00,  2.23it/s]\n",
    "\n",
    "\n",
    "Epochs: 1 | Train Loss:  0.285             | Train Accuracy:  0.809             | Val Loss:  0.133             | Val Accuracy:  0.946"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "        model = model.cuda()\n",
    "        \n",
    "    # Tracking variables\n",
    "    predictions_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in tqdm(test_dataloader):\n",
    "\n",
    "            test_label = test_label.to(device)\n",
    "            mask = test_input['attention_mask'].to(device)\n",
    "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "            output = model(input_id, mask)\n",
    "\n",
    "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "            total_acc_test += acc\n",
    "            \n",
    "            # add original labels\n",
    "            true_labels += test_label.cpu().numpy().flatten().tolist()\n",
    "            # get predicitons to list\n",
    "            predictions_labels += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
    "    return true_labels, predictions_labels\n",
    "    \n",
    "true_labels, pred_labels = evaluate(model, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100%|██████████| 75/75 [00:06<00:00, 11.11it/s]\n",
    "\n",
    "Test Accuracy:  0.973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix.\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels, labels=range(len(labels)), normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(labels.keys()))\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix.\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels, labels=range(len(labels)), normalize='true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=list(labels.keys()))\n",
    "disp.plot(ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save trained model\n",
    "torch.save(model.state_dict(), \"./models/gpt2-text-classifier-model_test.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "model_new = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=5, max_seq_len=128, gpt_model_name=model)\n",
    "model_new.load_state_dict(torch.load(\"./models/gpt2-text-classifier-model_test.pt\"))\n",
    "model_new.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text = \"\"\"\n",
    "The UK has accused President Putin of plotting to install a pro-Moscow figure to lead Ukraine's government.\n",
    "The Foreign Office took the unusual step of naming former Ukrainian MP Yevhen Murayev as a potential Kremlin candidate.\n",
    "Russia has moved 100,000 troops near to its border with Ukraine but denies it is planning an invasion.\n",
    "UK ministers have warned that the Russian government will face serious consequences if there is an incursion.\n",
    "In a statement, Foreign Secretary Liz Truss said: \"The information being released today shines a light on the extent of Russian activity designed to subvert Ukraine, and is an insight into Kremlin thinking.\n",
    "\"Russia must de-escalate, end its campaigns of aggression and disinformation, and pursue a path of diplomacy.\"\n",
    "The Russian Ministry of Foreign Affairs tweeted that the Foreign Office was \"circulating disinformation\" and urged it to \"cease these provocative activities\" and \"stop spreading nonsense\".\n",
    "\"\"\"\n",
    "\n",
    "fixed_text = \" \".join(example_text.lower().split())\n",
    "print(fixed_text)\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model)\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model_input = tokenizer(fixed_text, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = model_input['attention_mask'].cpu()\n",
    "input_id = model_input[\"input_ids\"].squeeze(1).cpu()\n",
    "\n",
    "output = model_new(input_id, mask)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"business\",\n",
    "    1: \"entertainment\",\n",
    "    2: \"sport\",\n",
    "    3: \"tech\",\n",
    "    4: \"politics\"\n",
    "         }\n",
    "\n",
    "pred_label = labels_map[output.argmax(dim=1).item()]\n",
    "print(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_gpt2_playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
